{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b87540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions import Exponential, Uniform\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "from torch.autograd import Variable\n",
    "import itertools\n",
    "import math \n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e0e45",
   "metadata": {},
   "source": [
    "# Define Functions to Generate Shared Codebook (Randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41affdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy1(labels, base=2):\n",
    "    value,counts = np.unique(labels, return_counts=True)\n",
    "    return entropy(counts, base=base)\n",
    "\n",
    "def torch_to_numpy(tensor):\n",
    "    tensor=tensor.detach()\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        if tensor.is_cuda:\n",
    "            tensor = tensor.cpu()\n",
    "        return tensor.numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a Torch tensor.\")\n",
    "\n",
    "def generate_logexp(B=128, N=1024):\n",
    "    exp = torch.cuda.FloatTensor(B, N, 1).exponential_()\n",
    "    return torch.log(exp)\n",
    "\n",
    "def generate_M(B=128, N=1024, dim=1, L=2): #log_2(L) bits only\n",
    "    \"\"\"random_tensor = torch.cuda.FloatTensor(B, N).random_(L).long()\n",
    "    return random_tensor\"\"\"\n",
    "    #random_tensor = torch.cuda.FloatTensor(B, N).random_(L).long()\n",
    "    M = np.arange(L)\n",
    "    M = np.repeat(M, int(N/L))\n",
    "    M = torch.from_numpy(M).cuda() #torch.Tensor(M).cuda()\n",
    "    \"\"\"M = torch.arange(L).cuda()\n",
    "    M = M.repeat(int(N/L))\"\"\"\n",
    "    M = M[None, ...].long()\n",
    "    return M\n",
    "\n",
    "def generate_prior(B=128, N=1024, dim=1, var=1.01):\n",
    "    # Generate Gaussian samples with mean 0 and the predefined variance\n",
    "    gaussian_samples = torch.cuda.FloatTensor(B, N,dim).normal_(0, 1) * np.sqrt(var)\n",
    "    #torch.randn((B,N,dim )) * np.sqrt(var)\n",
    "    return gaussian_samples\n",
    "\n",
    "\n",
    "def generate_common_randn(B=128, N=1024,dim=1,L=2, var=1.01):\n",
    "    S = generate_logexp(B,N)\n",
    "    M = generate_M(B,N,1,L)\n",
    "    U = generate_prior(B, N, dim, var)\n",
    "    return (S, M, U)\n",
    "\n",
    "def gaussian_log_prob(x, mean, variance):\n",
    "    log_prob = -0.5 * (math.log(2 * math.pi * variance) + ((x - mean) ** 2) / variance)\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c887a91a",
   "metadata": {},
   "source": [
    "# Gumbel Max Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea9738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enc(logS_, U_, X_, var_u_, var_u_x_):\n",
    "\n",
    "    log_p_ = gaussian_log_prob(U_, 0, var_u_).sum(dim=-1, keepdim=True)\n",
    "    log_t_ = gaussian_log_prob(U_, X_, var_u_x_).sum(dim=-1, keepdim=True) # PROBABLY WRONG <PLEASE CHECK>\n",
    "    score_x_ = logS_ + log_p_ - log_t_\n",
    "    scale_ = logS_ + log_p_ \n",
    "    \n",
    "    argmin_indices_encoder_ = torch.argmin(score_x_, dim=1)\n",
    "    selected_values_ = U_[torch.arange(score_x_.shape[0]), argmin_indices_encoder_[:,0]]\n",
    "    return argmin_indices_encoder_, selected_values_, scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d48c6bf",
   "metadata": {},
   "source": [
    "# Experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8070502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_exp(N=2**20, b_size=1, dim=1, total_epochs=4096, mean_u_x = -1.0, mean_u_y = 1.0,\n",
    "                var_u_x= 1.0, var_u_y=1.0, var_u = 4.0):\n",
    "    c=0\n",
    "    with torch.no_grad():\n",
    "        list_index = []\n",
    "        wait_t = []\n",
    "        list_X = []\n",
    "        list_X_hat = []\n",
    "        \n",
    "        for tuoc in range(total_epochs):\n",
    "            #print (tuoc)\n",
    "            logS,_,U = generate_common_randn(B=b_size, N=N, dim=dim, L=2, var=var_u)\n",
    "            \n",
    "            logS = logS.cuda()\n",
    "            U = U.cuda()\n",
    "            argmin_idx_alice, val_alice,_ = compute_enc(logS, U, mean_u_x, var_u, var_u_x)\n",
    "            argmin_idx_bob, val_bob,_     = compute_enc(logS, U, mean_u_y, var_u, var_u_y)\n",
    "            \n",
    "            argmin_idx_alice = int(argmin_idx_alice.cpu().detach().numpy())\n",
    "            argmin_idx_bob = int(argmin_idx_bob.cpu().detach().numpy())\n",
    "            \n",
    "            if argmin_idx_alice == argmin_idx_bob:\n",
    "                c +=1\n",
    "                \n",
    "    return c/float(total_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c217293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72158/3534932613.py:15: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  exp = torch.cuda.FloatTensor(B, N, 1).exponential_()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.5\n",
      "0.75\n",
      "1.0\n",
      "1.25\n",
      "1.5\n",
      "1.75\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "means_=[0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "match=[]\n",
    "\n",
    "for mean in means_:\n",
    "    print (mean)\n",
    "    match.append(matching_exp(mean_u_x=-mean, mean_u_y=mean, total_epochs=2**15))\n",
    "means_ = np.asarray(means_)\n",
    "match = np.asarray(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 36}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.figure(figsize=(10.5, 12))\n",
    "plt.rc('grid', linestyle=\"-\", color='grey')\n",
    "\n",
    "plt.plot(means_*2, 1-match, '-go', linewidth=4.0, markersize=15)   \n",
    "plt.ylabel(r'$P(U_p\\neq U_q)$', fontsize=55)\n",
    "plt.xlabel('$W_2(p_Y, q_Y)$', fontsize=55)\n",
    "\n",
    "plt.xticks(fontsize=50)\n",
    "plt.yticks(fontsize=50)\n",
    "\n",
    "#plt.title('Empirical Matching Probabilities')\n",
    "#plt.grid(True)\n",
    "plt.grid(linestyle='--',linewidth=0.8)\n",
    "\n",
    "#plt.savefig('match1.pdf',bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 36}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.figure(figsize=(10.5, 12))\n",
    "plt.rc('grid', linestyle=\"-\", color='grey')\n",
    "\n",
    "plt.plot(means_*2, 1-match, '-go', linewidth=4.0, markersize=15)   \n",
    "plt.ylabel(r'$P(U_p\\neq U_q)$', fontsize=55)\n",
    "plt.xlabel('$W_2(p_Y, q_Y)$', fontsize=55)\n",
    "\n",
    "plt.xticks(fontsize=50)\n",
    "plt.yticks(fontsize=50)\n",
    "\n",
    "#plt.title('Empirical Matching Probabilities')\n",
    "#plt.grid(True)\n",
    "plt.grid(linestyle='--',linewidth=0.8)\n",
    "\n",
    "#plt.savefig('match1.pdf',bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00f089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
